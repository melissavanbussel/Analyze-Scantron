test$edge_or_not[[i]] <- vector(length = test$num_choices_per_item[i])
for (j in 1:test$num_choices_per_item[i]) {
if (j == 1 | j == test$num_choices_per_item[i]) {
test$edge_or_not[[i]][j] <- "EDGE"
} else {
test$edge_or_not[[i]][j] <- "MIDDLE"
}
}
}
test$student_edge_avoidance_test_statistic_value <- vector(length = test$num_items)
for (i in 1:test$num_items) {
# what proportion of students should have picked edge cases, given that they got the question wrong?
# almost like an expected conditional probability
first_term_expected_proportion <- 1 - test$difficulty_indices[i]
second_term_expected_proportion <- length(which(test$edge_or_not[[i]][-letter2num(unlist(unname(test$answer_key[i])))] == "EDGE")) / length(test$distractors[[i]])
# expected proportion is "p" in the formula
expected_proportion <- first_term_expected_proportion * second_term_expected_proportion
# what proportion of students actually chose edge cases, given that they got the question wrong?
# conditional probability: P(chose edge | got it wrong)
# observed proportion is "phat" in the formula
observed_proportion <- sum(test$proportion_of_students_picking_choices[[i]][test$edge_or_not[[i]] == "EDGE"][-letter2num(unname(unlist(test$answer_key[i])))])
# hypothesis test on a single proportion. H0: phat = p, HA: phat < p (students are avoiding the edges)
# test statistic value for the hypothesis test: z = (p-phat)/(sqrt(p*(1-p)/n))
test$student_edge_avoidance_test_statistic_value[i] <- (expected_proportion - observed_proportion) / sqrt(expected_proportion * (1 - expected_proportion) / test$num_students)
}
test$mean_student_edge_avoidance_test_statistic_value <- mean(test$student_edge_avoidance_test_statistic_value, na.rm = TRUE)
test$answer_key_edge_or_not <- vector(length = test$num_items)
for (i in 1:test$num_items) {
test$answer_key_edge_or_not[i] <- test$edge_or_not[[i]][letter2num(unname(unlist(test$answer_key[i])))]
}
test$proportion_middle_answer_key <- length(which(test$answer_key_edge_or_not == "MIDDLE")) / length(test$answer_key_edge_or_not)
test$expected_proportion_middle_answer_key <- (mean(test$num_choices_per_item, na.rm = TRUE) - 2) / mean(test$num_choices_per_item, na.rm = TRUE)
# now do a hypothesis test; H0: true proportion of middle answer key = expected proportion of middle answer key; HA: true proportion > expected proportion (AKA, edge avoidance)
test$answer_key_test_statistic_value <- (test$expected_proportion_middle_answer_key - test$proportion_middle_answer_key) / sqrt(test$expected_proportion_middle_answer_key * (1 - test$expected_proportion_middle_answer_key) / test$num_items)
return(test)
}
exam <- read.table("~/ANTH 2122 JD SPRING 2015.csv", header = TRUE, stringsAsFactors = FALSE)
exam <- read.table("~/ANTH 2122 JD WINTER 2015.csv", header = TRUE, stringsAsFactors = FALSE)
exam <- read.table("~School/Trent/USRA/ANTH 2122 JD WINTER 2015.csv", header = TRUE, stringsAsFactors = FALSE)
exam <- read.table("~/School/Trent/USRA/ANTH 2122 JD WINTER 2015.csv", header = TRUE, stringsAsFactors = FALSE)
exam <- read.table("~/School/Trent/USRA/ANTH 2122 JD SPRING 2015.csv", header = TRUE, stringsAsFactors = FALSE)
exam
numchoicesperitem <- read_excel("~/School/Trent/USRA/file-number-2-for-app.csv")
numchoicesperitem <- read.csv("~/School/Trent/USRA/file-number-2-for-app.csv")
numchoicesperitem
str(numchoicesperitem)
numchoicesperitem <- read.csv("~/School/Trent/USRA/file-number-2-for-app.csv", header = FALSE, stringsAsFactors = FALSE)
str(numchoicesperitem)
numchoicesperitem <- as.vector(read.csv("~/School/Trent/USRA/file-number-2-for-app.csv", header = FALSE, stringsAsFactors =) FALSE)
numchoicesperitem <- as.vector(read.csv("~/School/Trent/USRA/file-number-2-for-app.csv", header = FALSE, stringsAsFactors = FALSE))
numchoicesperitem
str(numchoicesperitem)
str(as.vector(numchoicesperitem))
my_exam <- analyze_test_fast(exam, numchoicesperitem)
test$num_choices_per_item
correct_format <- function(exam) {
correct_format <- TRUE # initialize it to T, change to F if need be
if (names(exam[4]) != "Q1") {
correct_format <- FALSE
warning("Column 4 should correspond to Question 1")
}
if (exam[1,1] != 0) {
correct_format <- FALSE
warning("Row 1 (answer key) should have student ID listed as '0'")
}
# There should be no student answers with lowercase letters
student_answers <- paste(unique(unname(unlist(exam[,-c(1:3)]))), collapse = "")
if (student_answers != toupper(student_answers)) {
correct_format <- FALSE
warning("There is a lowercase letter in one of the student's solutions; there should only be uppercase letters")
}
if (NA %in% unique(unlist(exam[,-c(1:3)]))) {
correct_format <- FALSE
warning("There is an empty value somewhere in the dataset; it probably should say 'BLANK' instead, but please check this")
}
return(correct_format)
}
stopifnot(correct_format(exam) == TRUE)
test <- list()
class(test) <- "test"
test$year_level <- substring(exam[1, 3], 1, 1)
test$discipline <- exam[1, 2]
test$course_num <- exam[1, 3]
test$num_students <- nrow(exam) - 1 # subtract 1 since first row is answer key
test$num_items <- ncol(exam) - 3 # subtract 3 since first 3 columns are ID, DEPT, COURSE CODE
test$student_data <- exam[-1, -c(1:3)]
test$answer_key <- exam[1, 4:ncol(exam)]
valid_key <- vector(length = test$num_items)
for (i in 1:test$num_items) {
valid_key[i] <- (grepl(",", test$answer_key[i]) == FALSE) & (grepl("BLANK", test$answer_key[i]) == FALSE)
}
if (FALSE %in% valid_key) {
test$student_data <- test$student_data[, -(which(valid_key == FALSE))]
test$answer_key <- test$answer_key[-(which(valid_key == FALSE))]
test$num_items <- ncol(test$student_data)
if (length(which(valid_key == FALSE)) > 1) {
test$invalid_key <- paste("Some of your questions had ambiguous solutions; we are removing questions",
paste(which(valid_key == FALSE), collapse = ","),
"from the analysis", sep = " ")
warning(test$invalid_key)
} else {
test$invalid_key <- paste("One of your questions had an ambiguous solution; we are removing question",
paste(which(valid_key == FALSE), collapse = ","),
"from the analysis", sep = " ")
warning(test$invalid_key)
}
}
test$student_scores_item_included <- vector(length = test$num_students)
for (i in 1:test$num_students) {
test$student_scores_item_included[i] <- sum(test$answer_key == test$student_data[i,])
}
test$student_correct_or_not <- vector(length = test$num_items, mode = "list") # create list to store whether or not each student got each question correct
for (j in 1:test$num_students) {
for (i in 1:test$num_items) {
test$student_correct_or_not[[i]] <- test$answer_key[[i]] == test$student_data[1:nrow(test$student_data), i]
}
}
test$mean_student_scores <- mean(test$student_scores_item_included / test$num_items, na.rm = TRUE)
test$sd_student_scores <- sd(test$student_scores_item_included / test$num_items, na.rm = TRUE)
test$min_student_scores <- min(test$student_scores_item_included / test$num_items, na.rm = TRUE)
test$max_student_scores <- max(test$student_scores_item_included / test$num_items, na.rm = TRUE)
test$difficulty_indices <- vector(length = test$num_items)
for (i in 1:test$num_items) {
test$difficulty_indices[i] <- sum(test$student_correct_or_not[[i]]) / test$num_students
}
test$mean_difficulty_index <- mean(test$difficulty_indices, na.rm = TRUE)
test$sd_difficulty_index <- sd(test$difficulty_indices, na.rm = TRUE)
test$min_difficulty_index <- min(test$difficulty_indices, na.rm = TRUE)
test$max_difficulty_index <- max(test$difficulty_indices, na.rm = TRUE)
test$student_scores_item_excluded <- vector(length = test$num_items, mode = "list")
for (j in 1:test$num_items) {
temp <- vector(length = test$num_students)
for (i in 1:test$num_students) {
temp[i] <- test$student_scores_item_included[i] - sum(test$answer_key[[j]] == test$student_data[i, j])
}
test$student_scores_item_excluded[[j]] <- temp
}
test$r_prime_values <- vector(length = test$num_items)
for (i in 1:test$num_items) {
test$r_prime_values[i] <- cor(test$student_correct_or_not[[i]], test$student_scores_item_excluded[[i]] / test$num_items)
}
test$mean_r_prime_values <- mean(test$r_prime_values, na.rm = TRUE)
test$sd_r_prime_values <- sd(test$r_prime_values, na.rm = TRUE)
test$min_r_prime_values <- min(test$r_prime_values, na.rm = TRUE)
test$max_r_prime_values <- max(test$r_prime_values, na.rm = TRUE)
test$r_prime_values_less_than_given_number <- sum(test$r_prime_values < 0.1, na.rm = TRUE) / ( length(test$r_prime_values) - length(which(is.na(test$r_prime_values) == TRUE)) )
if (!is.null(numchoicesperitem)) {
test$num_choices_per_item <- numchoicesperitem
} else {
test$num_choices_per_item <- vector(length = test$num_items)
for (j in 1:test$num_items) {
temp <- vector(length = test$num_students)
for (i in 1:test$num_students) {
if (test$student_data[i,j] != "BLANK" & grepl(",", test$student_data[i,j]) == FALSE ) {
temp[i] <- letter2num(unlist(test$student_data[i, j]))
}
}
test$num_choices_per_item[j] <- max(temp)
}
}
letter2num <- function(x) {
stopifnot(x %in% LETTERS[1:26])
utf8ToInt(x) - utf8ToInt("A") + 1L
}
letters_of_alphabet <- LETTERS[1:26]
test$proportion_of_students_picking_choices <- vector(length = test$num_items, mode = "list")
for (j in 1:test$num_items) {
results <- vector(length = test$num_choices_per_item[j])
for (i in 1:test$num_choices_per_item[j]) {
selected <- vector(length = test$num_students)
for (k in 1:test$num_students) {
selected[k] <- match(test$student_data[k, j], letters_of_alphabet) == i
}
results[i] <- length(which(selected == TRUE)) / test$num_students
}
test$proportion_of_students_picking_choices[[j]] <- results
names(test$proportion_of_students_picking_choices[[j]]) <- LETTERS[1:test$num_choices_per_item[j]]
}
test$num_choices_per_item
test$num_choices_per_item
if (!is.null(numchoicesperitem)) {
test$num_choices_per_item <- as.vector(numchoicesperitem)
} else {
test$num_choices_per_item <- vector(length = test$num_items)
for (j in 1:test$num_items) {
temp <- vector(length = test$num_students)
for (i in 1:test$num_students) {
if (test$student_data[i,j] != "BLANK" & grepl(",", test$student_data[i,j]) == FALSE ) {
temp[i] <- letter2num(unlist(test$student_data[i, j]))
}
}
test$num_choices_per_item[j] <- max(temp)
}
}
letter2num <- function(x) {
stopifnot(x %in% LETTERS[1:26])
utf8ToInt(x) - utf8ToInt("A") + 1L
}
test$num_choices_per_item
test$num_choices_per_item <- unlist(numchoicesperitem)
if (!is.null(numchoicesperitem)) {
test$num_choices_per_item <- unlist(numchoicesperitem)
} else {
test$num_choices_per_item <- vector(length = test$num_items)
for (j in 1:test$num_items) {
temp <- vector(length = test$num_students)
for (i in 1:test$num_students) {
if (test$student_data[i,j] != "BLANK" & grepl(",", test$student_data[i,j]) == FALSE ) {
temp[i] <- letter2num(unlist(test$student_data[i, j]))
}
}
test$num_choices_per_item[j] <- max(temp)
}
}
test$num_choices_per_item
if (!is.null(numchoicesperitem)) {
test$num_choices_per_item <- unlist(unname(numchoicesperitem))
} else {
test$num_choices_per_item <- vector(length = test$num_items)
for (j in 1:test$num_items) {
temp <- vector(length = test$num_students)
for (i in 1:test$num_students) {
if (test$student_data[i,j] != "BLANK" & grepl(",", test$student_data[i,j]) == FALSE ) {
temp[i] <- letter2num(unlist(test$student_data[i, j]))
}
}
test$num_choices_per_item[j] <- max(temp)
}
}
letter2num <- function(x) {
stopifnot(x %in% LETTERS[1:26])
utf8ToInt(x) - utf8ToInt("A") + 1L
}
str(test$num_choices_per_item)
letter2num <- function(x) {
stopifnot(x %in% LETTERS[1:26])
utf8ToInt(x) - utf8ToInt("A") + 1L
}
letters_of_alphabet <- LETTERS[1:26]
test$proportion_of_students_picking_choices <- vector(length = test$num_items, mode = "list")
for (j in 1:test$num_items) {
results <- vector(length = test$num_choices_per_item[j])
for (i in 1:test$num_choices_per_item[j]) {
selected <- vector(length = test$num_students)
for (k in 1:test$num_students) {
selected[k] <- match(test$student_data[k, j], letters_of_alphabet) == i
}
results[i] <- length(which(selected == TRUE)) / test$num_students
}
test$proportion_of_students_picking_choices[[j]] <- results
names(test$proportion_of_students_picking_choices[[j]]) <- LETTERS[1:test$num_choices_per_item[j]]
}
test$total_number_of_distractors <- sum(test$num_choices_per_item - 1)
test$distractors <- vector(length = test$num_items, mode = "list")
for (i in 1:test$num_items) {
test$distractors[[i]] <- test$proportion_of_students_picking_choices[[i]][-(letter2num(as.character(test$answer_key[i])))]
}
test$non_functional_distractors_less_3 <- vector(length = test$num_items, mode = "list")
for (i in 1:test$num_items) {
test$non_functional_distractors_less_3[[i]] <- test$distractors[[i]][test$distractors[[i]] < 0.03]
}
p1 <- test$difficulty_indices
p2 <- 1-p1
test$cronbach_alpha <- test$num_items*(1-sum(p1*p2)/var(test$student_scores_item_included))/(test$num_items-1)
test$adjusted_cronbach_alpha <- ((50 / test$num_items)*(test$cronbach_alpha))/(1+((50.0/test$num_items)-1) * test$cronbach_alpha)
test$edge_or_not <- vector(length = test$num_items, mode = "list")
for (i in 1:test$num_items) {
test$edge_or_not[[i]] <- vector(length = test$num_choices_per_item[i])
for (j in 1:test$num_choices_per_item[i]) {
if (j == 1 | j == test$num_choices_per_item[i]) {
test$edge_or_not[[i]][j] <- "EDGE"
} else {
test$edge_or_not[[i]][j] <- "MIDDLE"
}
}
}
test$student_edge_avoidance_test_statistic_value <- vector(length = test$num_items)
for (i in 1:test$num_items) {
# what proportion of students should have picked edge cases, given that they got the question wrong?
# almost like an expected conditional probability
first_term_expected_proportion <- 1 - test$difficulty_indices[i]
second_term_expected_proportion <- length(which(test$edge_or_not[[i]][-letter2num(unlist(unname(test$answer_key[i])))] == "EDGE")) / length(test$distractors[[i]])
# expected proportion is "p" in the formula
expected_proportion <- first_term_expected_proportion * second_term_expected_proportion
# what proportion of students actually chose edge cases, given that they got the question wrong?
# conditional probability: P(chose edge | got it wrong)
# observed proportion is "phat" in the formula
observed_proportion <- sum(test$proportion_of_students_picking_choices[[i]][test$edge_or_not[[i]] == "EDGE"][-letter2num(unname(unlist(test$answer_key[i])))])
# hypothesis test on a single proportion. H0: phat = p, HA: phat < p (students are avoiding the edges)
# test statistic value for the hypothesis test: z = (p-phat)/(sqrt(p*(1-p)/n))
test$student_edge_avoidance_test_statistic_value[i] <- (expected_proportion - observed_proportion) / sqrt(expected_proportion * (1 - expected_proportion) / test$num_students)
}
test$mean_student_edge_avoidance_test_statistic_value <- mean(test$student_edge_avoidance_test_statistic_value, na.rm = TRUE)
test$answer_key_edge_or_not <- vector(length = test$num_items)
for (i in 1:test$num_items) {
test$answer_key_edge_or_not[i] <- test$edge_or_not[[i]][letter2num(unname(unlist(test$answer_key[i])))]
}
test$proportion_middle_answer_key <- length(which(test$answer_key_edge_or_not == "MIDDLE")) / length(test$answer_key_edge_or_not)
test$expected_proportion_middle_answer_key <- (mean(test$num_choices_per_item, na.rm = TRUE) - 2) / mean(test$num_choices_per_item, na.rm = TRUE)
test$answer_key_test_statistic_value <- (test$expected_proportion_middle_answer_key - test$proportion_middle_answer_key) / sqrt(test$expected_proportion_middle_answer_key * (1 - test$expected_proportion_middle_answer_key) / test$num_items)
analyze_test_fast <- function(exam, numchoicesperitem = NULL){
############################################## Error Checking ########################################################
correct_format <- function(exam) {
correct_format <- TRUE # initialize it to T, change to F if need be
if (names(exam[4]) != "Q1") {
correct_format <- FALSE
warning("Column 4 should correspond to Question 1")
}
if (exam[1,1] != 0) {
correct_format <- FALSE
warning("Row 1 (answer key) should have student ID listed as '0'")
}
# There should be no student answers with lowercase letters
student_answers <- paste(unique(unname(unlist(exam[,-c(1:3)]))), collapse = "")
if (student_answers != toupper(student_answers)) {
correct_format <- FALSE
warning("There is a lowercase letter in one of the student's solutions; there should only be uppercase letters")
}
if (NA %in% unique(unlist(exam[,-c(1:3)]))) {
correct_format <- FALSE
warning("There is an empty value somewhere in the dataset; it probably should say 'BLANK' instead, but please check this")
}
return(correct_format)
}
# Check if exam is of correct format
stopifnot(correct_format(exam) == TRUE)
############################################## Basic Test Information ################################################
test <- list()
class(test) <- "test"
test$year_level <- substring(exam[1, 3], 1, 1)
test$discipline <- exam[1, 2]
test$course_num <- exam[1, 3]
test$num_students <- nrow(exam) - 1 # subtract 1 since first row is answer key
test$num_items <- ncol(exam) - 3 # subtract 3 since first 3 columns are ID, DEPT, COURSE CODE
test$student_data <- exam[-1, -c(1:3)]
test$answer_key <- exam[1, 4:ncol(exam)]
# Check if the answer key is valid
valid_key <- vector(length = test$num_items)
for (i in 1:test$num_items) {
valid_key[i] <- (grepl(",", test$answer_key[i]) == FALSE) & (grepl("BLANK", test$answer_key[i]) == FALSE)
}
# Remove the questions with invalid solutions (more than one answer marked as correct, or no answer marked as correct)
# Tell the user that we're removing the questions that were ambiguous
if (FALSE %in% valid_key) {
test$student_data <- test$student_data[, -(which(valid_key == FALSE))]
test$answer_key <- test$answer_key[-(which(valid_key == FALSE))]
test$num_items <- ncol(test$student_data)
if (length(which(valid_key == FALSE)) > 1) {
test$invalid_key <- paste("Some of your questions had ambiguous solutions; we are removing questions",
paste(which(valid_key == FALSE), collapse = ","),
"from the analysis", sep = " ")
warning(test$invalid_key)
} else {
test$invalid_key <- paste("One of your questions had an ambiguous solution; we are removing question",
paste(which(valid_key == FALSE), collapse = ","),
"from the analysis", sep = " ")
warning(test$invalid_key)
}
}
############################################## Student Scores ########################################################
test$student_scores_item_included <- vector(length = test$num_students)
for (i in 1:test$num_students) {
test$student_scores_item_included[i] <- sum(test$answer_key == test$student_data[i,])
}
test$student_correct_or_not <- vector(length = test$num_items, mode = "list") # create list to store whether or not each student got each question correct
for (j in 1:test$num_students) {
for (i in 1:test$num_items) {
test$student_correct_or_not[[i]] <- test$answer_key[[i]] == test$student_data[1:nrow(test$student_data), i]
}
}
test$mean_student_scores <- mean(test$student_scores_item_included / test$num_items, na.rm = TRUE)
test$sd_student_scores <- sd(test$student_scores_item_included / test$num_items, na.rm = TRUE)
test$min_student_scores <- min(test$student_scores_item_included / test$num_items, na.rm = TRUE)
test$max_student_scores <- max(test$student_scores_item_included / test$num_items, na.rm = TRUE)
############################################## Difficulty Indices ####################################################
test$difficulty_indices <- vector(length = test$num_items)
for (i in 1:test$num_items) {
test$difficulty_indices[i] <- sum(test$student_correct_or_not[[i]]) / test$num_students
}
test$mean_difficulty_index <- mean(test$difficulty_indices, na.rm = TRUE)
test$sd_difficulty_index <- sd(test$difficulty_indices, na.rm = TRUE)
test$min_difficulty_index <- min(test$difficulty_indices, na.rm = TRUE)
test$max_difficulty_index <- max(test$difficulty_indices, na.rm = TRUE)
############################################## Item-excluded discrimination coefficient (rprime) #####################
test$student_scores_item_excluded <- vector(length = test$num_items, mode = "list")
for (j in 1:test$num_items) {
temp <- vector(length = test$num_students)
for (i in 1:test$num_students) {
temp[i] <- test$student_scores_item_included[i] - sum(test$answer_key[[j]] == test$student_data[i, j])
}
test$student_scores_item_excluded[[j]] <- temp
}
test$r_prime_values <- vector(length = test$num_items)
for (i in 1:test$num_items) {
test$r_prime_values[i] <- cor(test$student_correct_or_not[[i]], test$student_scores_item_excluded[[i]] / test$num_items)
}
test$mean_r_prime_values <- mean(test$r_prime_values, na.rm = TRUE)
test$sd_r_prime_values <- sd(test$r_prime_values, na.rm = TRUE)
test$min_r_prime_values <- min(test$r_prime_values, na.rm = TRUE)
test$max_r_prime_values <- max(test$r_prime_values, na.rm = TRUE)
test$r_prime_values_less_than_given_number <- sum(test$r_prime_values < 0.1, na.rm = TRUE) / ( length(test$r_prime_values) - length(which(is.na(test$r_prime_values) == TRUE)) )
############################################# Distractors ############################################################
# Check if the user's numchoicesperitem makes sense, if they chose to include it
if (!is.null(numchoicesperitem)) {
test$num_choices_per_item <- unlist(unname(numchoicesperitem))
} else {
test$num_choices_per_item <- vector(length = test$num_items)
for (j in 1:test$num_items) {
temp <- vector(length = test$num_students)
for (i in 1:test$num_students) {
if (test$student_data[i,j] != "BLANK" & grepl(",", test$student_data[i,j]) == FALSE ) {
temp[i] <- letter2num(unlist(test$student_data[i, j]))
}
}
test$num_choices_per_item[j] <- max(temp)
}
}
letter2num <- function(x) {
stopifnot(x %in% LETTERS[1:26])
utf8ToInt(x) - utf8ToInt("A") + 1L
}
letters_of_alphabet <- LETTERS[1:26]
test$proportion_of_students_picking_choices <- vector(length = test$num_items, mode = "list")
for (j in 1:test$num_items) {
results <- vector(length = test$num_choices_per_item[j])
for (i in 1:test$num_choices_per_item[j]) {
selected <- vector(length = test$num_students)
for (k in 1:test$num_students) {
selected[k] <- match(test$student_data[k, j], letters_of_alphabet) == i
}
results[i] <- length(which(selected == TRUE)) / test$num_students
}
test$proportion_of_students_picking_choices[[j]] <- results
names(test$proportion_of_students_picking_choices[[j]]) <- LETTERS[1:test$num_choices_per_item[j]]
}
test$total_number_of_distractors <- sum(test$num_choices_per_item - 1)
test$distractors <- vector(length = test$num_items, mode = "list")
for (i in 1:test$num_items) {
test$distractors[[i]] <- test$proportion_of_students_picking_choices[[i]][-(letter2num(as.character(test$answer_key[i])))]
}
test$non_functional_distractors_less_3 <- vector(length = test$num_items, mode = "list")
for (i in 1:test$num_items) {
test$non_functional_distractors_less_3[[i]] <- test$distractors[[i]][test$distractors[[i]] < 0.03]
}
############################################# Reliability ############################################################
p1 <- test$difficulty_indices
p2 <- 1-p1
test$cronbach_alpha <- test$num_items*(1-sum(p1*p2)/var(test$student_scores_item_included))/(test$num_items-1)
test$adjusted_cronbach_alpha <- ((50 / test$num_items)*(test$cronbach_alpha))/(1+((50.0/test$num_items)-1) * test$cronbach_alpha)
############################################# Edge Avoidance #########################################################
test$edge_or_not <- vector(length = test$num_items, mode = "list")
for (i in 1:test$num_items) {
test$edge_or_not[[i]] <- vector(length = test$num_choices_per_item[i])
for (j in 1:test$num_choices_per_item[i]) {
if (j == 1 | j == test$num_choices_per_item[i]) {
test$edge_or_not[[i]][j] <- "EDGE"
} else {
test$edge_or_not[[i]][j] <- "MIDDLE"
}
}
}
test$student_edge_avoidance_test_statistic_value <- vector(length = test$num_items)
for (i in 1:test$num_items) {
# what proportion of students should have picked edge cases, given that they got the question wrong?
# almost like an expected conditional probability
first_term_expected_proportion <- 1 - test$difficulty_indices[i]
second_term_expected_proportion <- length(which(test$edge_or_not[[i]][-letter2num(unlist(unname(test$answer_key[i])))] == "EDGE")) / length(test$distractors[[i]])
# expected proportion is "p" in the formula
expected_proportion <- first_term_expected_proportion * second_term_expected_proportion
# what proportion of students actually chose edge cases, given that they got the question wrong?
# conditional probability: P(chose edge | got it wrong)
# observed proportion is "phat" in the formula
observed_proportion <- sum(test$proportion_of_students_picking_choices[[i]][test$edge_or_not[[i]] == "EDGE"][-letter2num(unname(unlist(test$answer_key[i])))])
# hypothesis test on a single proportion. H0: phat = p, HA: phat < p (students are avoiding the edges)
# test statistic value for the hypothesis test: z = (p-phat)/(sqrt(p*(1-p)/n))
test$student_edge_avoidance_test_statistic_value[i] <- (expected_proportion - observed_proportion) / sqrt(expected_proportion * (1 - expected_proportion) / test$num_students)
}
test$mean_student_edge_avoidance_test_statistic_value <- mean(test$student_edge_avoidance_test_statistic_value, na.rm = TRUE)
test$answer_key_edge_or_not <- vector(length = test$num_items)
for (i in 1:test$num_items) {
test$answer_key_edge_or_not[i] <- test$edge_or_not[[i]][letter2num(unname(unlist(test$answer_key[i])))]
}
test$proportion_middle_answer_key <- length(which(test$answer_key_edge_or_not == "MIDDLE")) / length(test$answer_key_edge_or_not)
test$expected_proportion_middle_answer_key <- (mean(test$num_choices_per_item, na.rm = TRUE) - 2) / mean(test$num_choices_per_item, na.rm = TRUE)
# now do a hypothesis test; H0: true proportion of middle answer key = expected proportion of middle answer key; HA: true proportion > expected proportion (AKA, edge avoidance)
test$answer_key_test_statistic_value <- (test$expected_proportion_middle_answer_key - test$proportion_middle_answer_key) / sqrt(test$expected_proportion_middle_answer_key * (1 - test$expected_proportion_middle_answer_key) / test$num_items)
return(test)
}
return(test)
runApp('~/School/Trent/USRA/Shiny')
runApp('~/School/Trent/USRA/Shiny')
runApp('~/School/Trent/USRA/Shiny')
runApp('~/School/Trent/USRA/Shiny')
substr("blah.csv", start = -1, stop = -4)
?substr
substring("myblah.csv", start = 1, stop = 4)
substr("myblah.csv", start = 1, stop = 4)
substr("myblah.csv", start = -1, stop = 4)
substr("myblah.csv", start = length("myblah.csv"), stop = length("myblah.csv") - 3)
substr("myblah.csv", start = length("myblah.csv"), stop = length("myblah.csv") - 4)
library(stringi)
stri_sub("myblah.csv", start = -1, stop = -4)
substr("myblah.csv", start = -4, stop = -1)
stri_sub("myblah.csv", start = -4, stop = -1)
?stri_sub
stri_sub("myblah.csv", from = -4, to = -1)
library(readcl )
library(readxl )
?read_excel
runApp('~/School/Trent/USRA/Shiny')
runApp('~/School/Trent/USRA/Shiny')
runApp('~/School/Trent/USRA/Shiny')
